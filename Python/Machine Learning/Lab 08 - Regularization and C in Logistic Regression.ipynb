{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af0892f",
   "metadata": {},
   "source": [
    "The choice between using regularization and setting the value of C. In logistic regression depends on the specific \n",
    "characteristics of the dataset and the desired balance between bias and variance in the model.\n",
    "\n",
    "Here's a general guideline to help you decide:\n",
    "\n",
    "1. Regularization: Regularization is typically preferred when you have a high-dimensional dataset with many features, or when \n",
    "    you suspect that the model may be overfitting. Regularization helps prevent overfitting by penalizing large parameter \n",
    "    values, leading to a simpler model with improved generalization performance. If your dataset is noisy or contains outliers, \n",
    "    regularization can also help improve the model's robustness.\n",
    "\n",
    "2. Choosing C: Setting the value of C allows you to directly control the trade-off between fitting the training data well and \n",
    "    keeping the model's parameters small. A smaller \\(C\\) value corresponds to stronger regularization, while a larger C value \n",
    "    corresponds to weaker regularization. If you have prior knowledge about the importance of fitting the training data closely \n",
    "    versus preventing overfitting, you can adjust \\(C\\) accordingly. Additionally, you can use techniques like cross-validation \n",
    "    to find the optimal value of \\(C\\) that maximizes the model's performance on unseen data.\n",
    "\n",
    "In practice, it's often a good idea to start with regularization and then fine-tune the value of C through experimentation \n",
    "or cross-validation. Regularization helps prevent overfitting and provides a more stable foundation for tuning other \n",
    "hyperparameters. However, the choice ultimately depends on the specific requirements of your dataset and the goals of your \n",
    "modeling task. It's important to experiment with different approaches and evaluate their performance empirically to determine \n",
    "the most suitable strategy for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3450ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Select only the first two features for simplicity\n",
    "X = X[:, :2]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50645ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression without regularization (C=1)\n",
    "logreg_no_reg = LogisticRegression(C=1, solver='lbfgs', max_iter=1000)\n",
    "logreg_no_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train logistic regression with regularization (C=0.1)\n",
    "logreg_reg = LogisticRegression(C=0.1, solver='lbfgs', max_iter=1000)\n",
    "logreg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfbdc0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg_no_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report, accuracy_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate logistic regression without regularization\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred_no_reg \u001b[38;5;241m=\u001b[39m logreg_no_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m accuracy_no_reg \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_no_reg)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy without regularization:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_no_reg)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logreg_no_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate logistic regression without regularization\n",
    "y_pred_no_reg = logreg_no_reg.predict(X_test)\n",
    "accuracy_no_reg = accuracy_score(y_test, y_pred_no_reg)\n",
    "print(\"Accuracy without regularization:\", accuracy_no_reg)\n",
    "\n",
    "# Evaluate logistic regression with regularization\n",
    "y_pred_reg = logreg_reg.predict(X_test)\n",
    "accuracy_reg = accuracy_score(y_test, y_pred_reg)\n",
    "print(\"Accuracy with regularization:\", accuracy_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519e015",
   "metadata": {},
   "source": [
    "In mathematics, the norm of a vector is a measure of its length or size. It's a way to quantify the distance or magnitude of \n",
    "a vector. \n",
    "The most commonly used norm is the Euclidean norm, also known as the L2 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7f24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the vector: 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a vector\n",
    "v = np.array([3, 4])\n",
    "\n",
    "# Compute the norm (L2 norm) of the vector\n",
    "norm = np.linalg.norm(v)\n",
    "\n",
    "print(\"Norm of the vector:\", norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b186f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
